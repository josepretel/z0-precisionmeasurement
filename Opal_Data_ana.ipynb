{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import mplhep\n",
    "%matplotlib inline \n",
    "#%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from brokenaxes import brokenaxes\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Measurement of the total production cross sections\n",
    "\n",
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanenergy = np.array([88.47939, 89.46793, 90.22266, 91.22430, 91.96648, 92.96465, 93.71712])\n",
    "lumi = np.array([463.9790, 667.5236, 486.7641, 2246.568, 535.9080, 450.6000, 709.6980])\n",
    "stat = np.array([2.902361, 3.521166, 3.033955, 6.603405, 3.265110, 3.027953, 3.819882])\n",
    "sys = np.array([3.104100, 4.471900, 3.261500, 15.04780, 3.585300, 3.020000, 4.762000])\n",
    "all = np.array([4.249604, 5.691792, 4.454466, 16.43293, 4.849260, 4.276552, 6.104764])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Open file\n",
    "\n",
    "file_Opal = uproot.open('daten_4.root')\n",
    "ttree_name_Opal = 'myTTree'\n",
    "\n",
    "### Print list of 'branches' of the TTree (i.e. list of variable names)\n",
    "print('Opal',file_Opal[ttree_name_Opal].keys())\n",
    "\n",
    "## Load branches\n",
    "branches_Opal = file_Opal[ttree_name_Opal].arrays()\n",
    "\n",
    "var_Pcharged = 'Pcharged'\n",
    "pchar_Opal = ak.to_numpy(branches_Opal[var_Pcharged])\n",
    "\n",
    "var_Ncharged = 'Ncharged'\n",
    "nchar_Opal = ak.to_numpy(branches_Opal[var_Ncharged])\n",
    "\n",
    "var_E_ecal = 'E_ecal'\n",
    "E_ecal_Opal = ak.to_numpy(branches_Opal[var_E_ecal])\n",
    "\n",
    "var_E_hcal = 'E_hcal'\n",
    "E_hcal_Opal = ak.to_numpy(branches_Opal[var_E_hcal])\n",
    "\n",
    "var_cos_thet = 'cos_thet'\n",
    "cos_thet_Opal = ak.to_numpy(branches_Opal[var_cos_thet])\n",
    "\n",
    "var_E_lep = 'E_lep'\n",
    "E_lep_Opal = ak.to_numpy(branches_Opal[var_E_lep]) \n",
    "\n",
    "print(f\"Opal {E_lep_Opal} min: {E_lep_Opal.min()}, max: {E_lep_Opal.max()}\")\n",
    "\n",
    "data_Opal = pd.DataFrame({'COM_energy':np.zeros(len(nchar_Opal)), 'ID': np.chararray(len(nchar_Opal)),'Ncharged': nchar_Opal, 'Pcharged': pchar_Opal, 'E_ecal': E_ecal_Opal, 'E_hcal': E_hcal_Opal, 'E_lep':E_lep_Opal, 'cos_thet': cos_thet_Opal})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate the 7 different energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sevenEnergies(E_lep):\n",
    "    Energies = np.array([])\n",
    "    for i in range(len(E_lep)):\n",
    "        if 2*E_lep[i]<(meanenergy[0]+meanenergy[1])/2:\n",
    "            Energies = np.append(Energies,meanenergy[0])\n",
    "\n",
    "        elif 2*E_lep[i]<(meanenergy[1]+meanenergy[2])/2:\n",
    "            Energies = np.append(Energies,meanenergy[1])\n",
    "\n",
    "        elif 2*E_lep[i]<(meanenergy[2]+meanenergy[3])/2:\n",
    "            Energies = np.append(Energies,meanenergy[2])\n",
    "\n",
    "        elif 2*E_lep[i]<(meanenergy[3]+meanenergy[4])/2:\n",
    "            Energies = np.append(Energies,meanenergy[3])\n",
    "\n",
    "        elif 2*E_lep[i]<(meanenergy[4]+meanenergy[5])/2:\n",
    "            Energies = np.append(Energies,meanenergy[4])\n",
    "        \n",
    "        elif 2*E_lep[i]<(meanenergy[5]+meanenergy[6])/2:\n",
    "            Energies = np.append(Energies,meanenergy[5])\n",
    "        \n",
    "        else:\n",
    "            Energies = np.append(Energies,meanenergy[6])\n",
    "\n",
    "    return Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Opal.loc[:, ['COM_energy']] = sevenEnergies(data_Opal['E_lep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(mplhep.style.ATLAS) # You can load ATLAS/CMS/ALICE plot style \n",
    "ratio = [1,4] # ratio of the two subplots\n",
    "\n",
    "#Opal\n",
    "\n",
    "bin_content_Opal, bin_edges_Opal, _ = plt.hist(data_Opal.loc[data_Opal['E_lep'] == 44.732]['E_ecal'],bins=50, histtype='step',  linewidth=2, edgecolor='b', hatch='/', label='E_cal Opal')\n",
    "mid_Opal = 0.5*(bin_edges_Opal[1:] + bin_edges_Opal[:-1]) #Calculate midpoint of the bars\n",
    "\n",
    "error_sizes = np.sqrt(bin_content_Opal)\n",
    "\n",
    "plt.errorbar(mid_Opal, bin_content_Opal, yerr=error_sizes, fmt='none')\n",
    "\n",
    "\n",
    "#plt.ylim(0, 0.7*10**4)  # most of the data\n",
    "\n",
    "\n",
    "\n",
    "### Show the plot on screen\n",
    "plt.xlim(0,150)\n",
    "plt.legend(loc = 4)\n",
    "plt.xlabel('E_ecal')\n",
    "plt.ylabel('Number of events')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First determine the number of events in the handronic channel *and* in the three leptonic channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ratio= 0.470464817345979\n",
    "sigma_ratio = 0.005072534012880613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_event_in_4CH(Ncharged, Pcharged, E_ecal, E_hcal, cos_thet):\n",
    "    if len(Ncharged)==len(Pcharged)==len(E_ecal)==len(E_hcal):\n",
    "        #print(Ncharged)\n",
    "        PI = np.chararray((len(Ncharged),1), itemsize=2)[:]\n",
    "        PI[:] = 'NC'      # create start PI array with all events unclassified\n",
    "        NC = 0      \n",
    "        ee = 0 \n",
    "        es = 0     \n",
    "        qq = 0\n",
    "        mm = 0\n",
    "        tt = 0\n",
    "        #print(f'Classification for Energy {meanenergy[I]}:\\n')                 \n",
    "        for i in range(len(Ncharged)):\n",
    "            \n",
    "            if (Ncharged[i] >= 7) & (E_ecal[i]>20):\n",
    "                PI[i] = \"qq\"\n",
    "                qq += 1\n",
    "            elif (E_ecal[i] >= 60): # electron s channel cut\n",
    "                PI[i] = \"ee\"\n",
    "                ee += 1\n",
    "            elif (70<=Pcharged[i] <= 110) & (E_ecal[i] < 20):\n",
    "                PI[i] = \"mm\"\n",
    "                mm += 1\n",
    "            elif (Pcharged[i] < 10) & (E_ecal[i] < 10):\n",
    "                PI[i] = \"mm\"\n",
    "                mm += 1\n",
    "            elif (E_ecal[i] < 100) & (1 < Pcharged[i] < 75):\n",
    "                PI[i] = \"tt\"\n",
    "                tt += 1\n",
    "            else:\n",
    "                PI[i] = \"NC\"\n",
    "                NC += 1\n",
    "        L = len(Ncharged) * 0.470464817345979 # take into account that we only look at the S-channel hece 'Lenght' (total number of events are only number of all ee events times s-channel frac)\n",
    "        for i in range(len(Ncharged)):\n",
    "            if (PI[i] == b'ee') & (-0.9 < cos_thet[i] < 0.1): # electron s channel cut\n",
    "                PI[i] = \"es\"\n",
    "                es += 1 * 2.144772117962466 # correct for only selecting part of the S_channel\n",
    "        #print(PI)\n",
    "        print('ee, mm, tt, qq, NC,len(Ncharged)')\n",
    "        print(ee, mm, tt, qq, NC,len(Ncharged))\n",
    "        print()\n",
    "    else:\n",
    "        print('Unequaly long input arrays')\n",
    "    return [[ee, mm, tt, qq, NC, len(Ncharged)], PI, [es/L, mm/len(Ncharged), tt/len(Ncharged), qq/len(Ncharged), NC/len(Ncharged)],[es, mm, tt, qq, NC, len(Ncharged)]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add particle ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchar = data_Opal['Ncharged'].to_numpy()\n",
    "pchar = data_Opal['Pcharged'].to_numpy()\n",
    "E_ecal = data_Opal['E_ecal'].to_numpy()\n",
    "E_hcal = data_Opal['E_hcal'].to_numpy()\n",
    "cos_thet = data_Opal['cos_thet'].to_numpy()\n",
    "data_Opal.loc[:, ['ID']] = classify_event_in_4CH(nchar, pchar, E_ecal, E_hcal, cos_thet)[1]\n",
    "#len(classify_event_in_4CH(nchar, pchar, E_ecal, E_hcal, i)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create callification Matrix sorted by energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_Opal = np.zeros((7,6))\n",
    "for i in range(0,7,1):\n",
    "    print(i)\n",
    "    nchar = data_Opal.loc[data_Opal['COM_energy'] == meanenergy[i]]['Ncharged'].to_numpy()\n",
    "    pchar = data_Opal.loc[data_Opal['COM_energy'] == meanenergy[i]]['Pcharged'].to_numpy()\n",
    "    E_ecal = data_Opal.loc[data_Opal['COM_energy'] == meanenergy[i]]['E_ecal'].to_numpy()\n",
    "    E_hcal = data_Opal.loc[data_Opal['COM_energy'] == meanenergy[i]]['E_hcal'].to_numpy()\n",
    "    cos_thet = data_Opal.loc[data_Opal['COM_energy'] == meanenergy[i]]['cos_thet'].to_numpy()\n",
    "    classify_Opal[i] = classify_event_in_4CH(nchar, pchar, E_ecal, E_hcal, cos_thet)[3]\n",
    "classify_Opal_error = np.sqrt(classify_Opal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_Opal_df = pd.DataFrame(dict(zip(['es', 'mm', 'tt', 'qq', 'NC','length'], classify_Opal.transpose())))\n",
    "classify_Opal_df['CMS_energies'] = meanenergy\n",
    "classify_Opal_df = classify_Opal_df.join(pd.DataFrame(classify_Opal_error[:, :4], columns = ['es_u', 'mm_u', 'tt_u', 'qq_u']))\n",
    "classify_Opal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.hist(data_Opal[(data_Opal['COM_energy'] == meanenergy[i]) & (data_Opal['ID'] == b'ee') & (data_Opal['cos_thet']<=0.25)]['E_ecal'].to_numpy(), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_Opal[(data_Opal['ID'] == b'ee') & (data_Opal['cos_thet']>1)]['cos_thet'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_Opal[(data_Opal['ID'] == b'ee')]['cos_thet'].to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct background and efficency \n",
    "\n",
    "* $N_{cut corr} = N_{cut} \\epsilon^{-1}$\n",
    "\n",
    "To get the error on the background and efficency corrected data one has to propagate the $\\sqrt{N}$ error with the error of the inverse efficency matrix calculated using a toy MC and propagate it using gaussian error propagation.\n",
    "* $\\Delta N_{cut corr} = \\sqrt{(\\Delta N_{cut} \\epsilon^{-1})^{2} + (N_{cut} \\Delta \\epsilon^{-1})^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix = np.array([[9.44358862e-01, 0.00000000e+00, 1.06607535e-03, 2.66518838e-04,\n",
    "        4.60544551e-03],\n",
    "       [2.01311705e-05, 9.47722529e-01, 3.42865619e-02, 0.00000000e+00,\n",
    "        1.79697185e-02],\n",
    "       [3.82571263e-02, 7.73853107e-03, 9.26237786e-01, 1.13995001e-02,\n",
    "        1.43535234e-02],\n",
    "       [9.34935016e-04, 5.07289754e-05, 4.24094234e-03, 9.94561854e-01,\n",
    "        1.62332721e-04]])\n",
    "\n",
    "\n",
    "Matrix_inv = np.linalg.inv(Matrix[:, :4])\n",
    "\n",
    "\n",
    "Matrix_error_inv = np.array([[4.87418322e-03, 9.46085523e-07, 1.15537576e-04, 1.06662703e-04],\n",
    "                             [3.01977613e-05, 4.92789228e-03, 7.24046709e-04, 1.80927276e-04],\n",
    "                             [2.31450425e-04, 4.15124017e-05, 2.40414630e-04, 5.00395757e-03],\n",
    "                             [7.65248259e-04, 3.12274846e-04, 5.14290685e-03, 4.08665348e-04]])[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncutcorr = np.zeros((7,4))\n",
    "Ncutcorr_err = np.zeros((7,4))\n",
    "Sigma = np.zeros((7,4))\n",
    "Sigma_err = np.zeros((7,4))\n",
    "for i in range(0,7,1):\n",
    "    N_df = pd.DataFrame(classify_Opal_df.loc[classify_Opal_df['CMS_energies'] == meanenergy[i],['es', 'mm', 'tt', 'qq']])\n",
    "    N_err_df = pd.DataFrame(classify_Opal_df.loc[classify_Opal_df['CMS_energies'] == meanenergy[i],['es_u', 'mm_u', 'tt_u', 'qq_u']])\n",
    "    N = np.reshape(N_df.to_numpy(dtype=float),4)\n",
    "    N_err = np.reshape(N_err_df.to_numpy(dtype=float),4)\n",
    "    Ncor = N.dot(Matrix_inv)\n",
    "    Nerrcor = np.sqrt( np.square( N.dot(Matrix_error_inv) )+ np.square( N_err.dot(Matrix_inv) ))\n",
    "    Ncutcorr[i] = Ncor\n",
    "    Ncutcorr_err[i] = Nerrcor\n",
    "    sig = Ncor / lumi[i]\n",
    "    sig_err = np.sqrt( np.square( Nerrcor / lumi[i]) + np.sqrt(Ncor / (lumi[i]**2) * all[i]) )\n",
    "    Sigma[i] = sig\n",
    "    Sigma_err[i] = sig_err\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radiation corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadronic = [2.0, 4.3, 7.7, 10.8, 4.7, -0.2, -1.6]\n",
    "leptonic = [0.09, 0.20, 0.36, 0.52, 0.22, -0.01, -0.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3,1):\n",
    "    Sigma[:,i] = Sigma[:,i]+leptonic\n",
    "\n",
    "Sigma[:,3] = Sigma[:,3]+hadronic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncutcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncutcorr_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['electron', 'myon', 'tau', 'hadron']\n",
    "for i in range(0,4,1):\n",
    "        plt.errorbar(meanenergy,Sigma[:,i], yerr=Sigma_err[:,i] ,marker ='x', ls= '', ms = 8, capsize=2, capthick=0.5,ecolor='black', elinewidth=0.5, label=f'{name[i]}')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['electron', 'myon', 'tau', 'hadron']\n",
    "for i in range(0,3,1):\n",
    "        plt.errorbar(meanenergy,Sigma[:,i], yerr=Sigma_err[:,i] ,marker ='x', ls= '', ms = 8, capsize=2, capthick=0.5,ecolor='black', elinewidth=0.5, label=f'{name[i]}')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativistic_breit_wigner(x, resonance_mass, width, normalization):\n",
    "    gamma = np.sqrt(resonance_mass ** 2 * (resonance_mass ** 2 + width ** 2))\n",
    "    k = 2.0 * np.sqrt(2) * resonance_mass * width * gamma / (np.pi * np.sqrt(resonance_mass ** 2 + gamma))\n",
    "    return normalization * k / ((x ** 2 - resonance_mass ** 2) ** 2 + resonance_mass ** 2 * width ** 2)\n",
    "\n",
    "MZarray = np.zeros(4)\n",
    "MZarray_err = np.zeros(4)\n",
    "widtharray = np.zeros(4)\n",
    "widtharray_err = np.zeros(4)\n",
    "crossectionmax = np.zeros(4)\n",
    "crossectionmax_err = np.zeros(4)\n",
    "    \n",
    "for i in range(0,4,1):\n",
    "    popt, pcov = curve_fit(relativistic_breit_wigner, meanenergy,Sigma[:,i], sigma = Sigma_err[:,i], p0=[90, 10, 30], maxfev = 8000)\n",
    "    x = np.linspace(80, 100, 200)\n",
    "    y = relativistic_breit_wigner(x, *popt)\n",
    "    y_errp = relativistic_breit_wigner(x, popt[0]+np.sqrt(pcov[0][0]), popt[1]+np.sqrt(pcov[1][1]), popt[2]+np.sqrt(pcov[2][2]))\n",
    "    y_errm = relativistic_breit_wigner(x, popt[0]-np.sqrt(pcov[0][0]), popt[1]-np.sqrt(pcov[1][1]), popt[2]-np.sqrt(pcov[2][2]))\n",
    "    plt.plot(x, y, label=f'Fit{i} params = {popt[0]:.2f}, {popt[1]:.2f}, {popt[2]:.2f}')\n",
    "    #plt.plot(x, y_err, label=f'Fit{i} params = {popt[0]:.2f}, {popt[1]:.2f}, {popt[2]:.2f}')\n",
    "    plt.errorbar(meanenergy,Sigma[:,i], yerr=Sigma_err[:,i] ,marker ='x', ls= '', ms = 8, capsize=2, capthick=0.5,ecolor='black', elinewidth=0.5, label=f'{i}')\n",
    "    print(popt)\n",
    "    print()\n",
    "    print(np.sqrt(pcov))\n",
    "    print('---------------')\n",
    "    MZarray[i] = popt[0]\n",
    "    widtharray[i] =  popt[1]\n",
    "    crossectionmax[i] = max(y)\n",
    "    MZarray_err[i] = np.sqrt(pcov[0][0])\n",
    "    widtharray_err[i] =  np.sqrt(pcov[1][1])\n",
    "    crossectionmax_err[i] = np.mean([abs(max(y)-max(y_errp)),abs(max(y)-max(y_errm))])\n",
    "plt.xlabel('CMS energy \\GeV')\n",
    "plt.ylabel('crossection\\ nb')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativistic_breit_wigner(x, resonance_mass, width, normalization):\n",
    "    gamma = np.sqrt(resonance_mass ** 2 * (resonance_mass ** 2 + width ** 2))\n",
    "    k = 2.0 * np.sqrt(2) * resonance_mass * width * gamma / (np.pi * np.sqrt(resonance_mass ** 2 + gamma))\n",
    "    return normalization * k / ((x ** 2 - resonance_mass ** 2) ** 2 + resonance_mass ** 2 * width ** 2)\n",
    "\n",
    "\n",
    "for i in range(0,3,1):\n",
    "    popt, pcov = curve_fit(relativistic_breit_wigner, meanenergy,Sigma[:,i], sigma = Sigma_err[:,i], p0=[90, 10, 30], maxfev = 8000)\n",
    "    x = np.linspace(80, 100, 200)\n",
    "    y = relativistic_breit_wigner(x, *popt)\n",
    "    y_err = relativistic_breit_wigner(x, popt[0]+np.sqrt(pcov[0][0]), popt[1]+np.sqrt(pcov[1][1]), popt[2]+np.sqrt(pcov[2][2]))\n",
    "    plt.plot(x, y, label=f'Fit{i} params = {popt[0]:.2f}, {popt[1]:.2f}, {popt[2]:.2f}')\n",
    "    #plt.plot(x, y_err, label=f'Fit{i} params = {popt[0]:.2f}, {popt[1]:.2f}, {popt[2]:.2f}')\n",
    "    plt.errorbar(meanenergy,Sigma[:,i], yerr=Sigma_err[:,i] ,marker ='x', ls= '', ms = 8, capsize=2, capthick=0.5,ecolor='black', elinewidth=0.5, label=f'{i}')\n",
    "    print(popt)\n",
    "    print()\n",
    "    print(np.sqrt(pcov))\n",
    "    print('---------------')\n",
    "plt.xlabel('CMS energy \\GeV')\n",
    "plt.ylabel('crossection\\ nb')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## partial decay width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(widtharray)\n",
    "print()\n",
    "print(MZarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    values, weights -- NumPy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    return (average, np.sqrt(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MZ, MZ_err = weighted_avg_and_std(MZarray, MZarray_err)\n",
    "#MZ_err = np.average(MZarray, weights=MZarray_err)\n",
    "print(f'the Z0 mass is {MZ} with a stat. uncertainty of {MZ_err}')\n",
    "width, width_err = weighted_avg_and_std(widtharray, widtharray_err)\n",
    "#width_err = np.std(widtharray)\n",
    "print(f'\\nthe decay width of Z0 is {width} with a stat. uncertainty of {width_err}')\n",
    "\n",
    "#print(crossectionmax)   # nB = (h_bar*c/624)^2 * GeV^-2\n",
    "\n",
    "                        # Mz --> GeV,  width--> Gev\n",
    "h_bar= 6.582119569*10**(-25) #GeV⋅s\n",
    "c_light= 299792458 # m/s\n",
    "\n",
    "Gamma_e = np.sqrt((crossectionmax[0]/624**2) * MZ**2 * width**2 / (12 * np.pi))\n",
    "Gamma_m = ((crossectionmax[1]/624**2) * MZ**2 * width**2) / (12 * np.pi * Gamma_e)\n",
    "Gamma_t = ((crossectionmax[2]/624**2) * MZ**2 * width**2) / (12 * np.pi * Gamma_e)\n",
    "Gamma_q = ((crossectionmax[3]/624**2) * MZ**2 * width**2) / (12 * np.pi * Gamma_e)\n",
    "\n",
    "Gamma_e_err = np.sqrt( np.square( MZ**2 *width**2 / ( 4672512 * np.pi) * crossectionmax_err[0]) + np.square(crossectionmax[0] * MZ * width**2 / (2336256 * np.pi) * MZ_err) + np.square( crossectionmax[0] * MZ**2 * width / (2336256 *np.pi ) * width_err))\n",
    "\n",
    "Gamma_m_err = np.sqrt(np.square(MZ**2 * width**2 / (4672512 * np.pi * Gamma_e) * crossectionmax_err[1]) + np.square(crossectionmax[1] * MZ * width**2 / ( 2336256 * np.pi * Gamma_e) * MZ_err) + np.square( crossectionmax[1] * MZ * width / ( 2336256 * np.pi * Gamma_e) * width_err)+ np.square(crossectionmax[1] * MZ**2 * width**2 / (4672512 * np.pi * Gamma_e**2) * Gamma_e_err))\n",
    "Gamma_t_err = np.sqrt(np.square(MZ**2 * width**2 / (4672512 * np.pi * Gamma_e) * crossectionmax_err[2]) + np.square(crossectionmax[2] * MZ * width**2 / ( 2336256 * np.pi * Gamma_e) * MZ_err) + np.square( crossectionmax[2] * MZ * width / ( 2336256 * np.pi * Gamma_e) * width_err)+ np.square(crossectionmax[2] * MZ**2 * width**2 / (4672512 * np.pi * Gamma_e**2) * Gamma_e_err))\n",
    "Gamma_q_err = np.sqrt(np.square(MZ**2 * width**2 / (4672512 * np.pi * Gamma_e) * crossectionmax_err[3]) + np.square(crossectionmax[3] * MZ * width**2 / ( 2336256 * np.pi * Gamma_e) * MZ_err) + np.square( crossectionmax[3] * MZ * width / ( 2336256 * np.pi * Gamma_e) * width_err)+ np.square(crossectionmax[3] * MZ**2 * width**2 / (4672512 * np.pi * Gamma_e**2) * Gamma_e_err))\n",
    "\n",
    "Gamma_v = width - Gamma_e - Gamma_m - Gamma_q - Gamma_t\n",
    "Gamma_v_err = np.sqrt( Gamma_e_err**2 + Gamma_m_err**2 + Gamma_t_err**2 + Gamma_q_err**2 + width_err**2)\n",
    "print(f'\\nPartial decay widths with stat uncertainty \\nGamma_e = {Gamma_e:.4f} \\pm {Gamma_e_err:.4f}; Gamma_m = {Gamma_m:.4f} \\pm {Gamma_m_err:.4f}; Gamma_t = {Gamma_t:.4f} \\pm {Gamma_t_err:.4f}; Gamma_q = {Gamma_q:.4f} \\pm {Gamma_q_err:.4f}; Gamma_v = {Gamma_v:.4f} \\pm {Gamma_v_err:.4f}')\n",
    "Gamma = np.array([Gamma_e, Gamma_m, Gamma_t, Gamma_q, Gamma_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossectionmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Backward-Forward-Symmetry $A_{FB}$ ##\n",
    "\n",
    "The $A_{FB} can be calculated by equation (19) of the english instuctions. To caluclate it with the methods we have, first eq(19) is simplified to\n",
    "\\begin{align}\n",
    "A_{FB}= \\frac{\\sigma_B-\\sigma_F}{\\sigma_B+\\sigma_F}\n",
    "\\end{align}\n",
    "\n",
    "with \n",
    "\n",
    "\\begin{align}\n",
    "\\sigma_{F,B} = \\frac{N_{F, B}}{\\int L dt}\n",
    "\\end{align}\n",
    "The numbers $N_{F,B}$ can be extracted from the myon plot of $\\cos_{thet}$ with conditions $\\lessgtr cos(\\theta)=0$, respectively.\n",
    "Therefore $A_{FB}$ becomes\n",
    "\\begin{align}\n",
    "A_{FB}= \\frac{N_B-N_F}{N_B+N_F}\n",
    "\\end{align}\n",
    "\n",
    "errors are calculated with gaussian error propagation, see 2nd code space after this markdown. Talks about the dependecies of the the symmetries with the COM-energy will be in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meanenergy = np.array([88.47939, 89.46793, 90.22266, 91.22430, 91.96648, 92.96465, 93.71712])\n",
    "\n",
    "A_FB= np.zeros(7)\n",
    "N_F_array = np.zeros(7)\n",
    "N_B_array = np.zeros(7)\n",
    "\n",
    "for i in range(0,7,1):\n",
    "\n",
    "    myon_cos= data_Opal[(data_Opal['ID']== b'mm') & (data_Opal['cos_thet']<200) & (data_Opal['COM_energy']==meanenergy[i])][\"cos_thet\"].to_numpy()\n",
    "    myon_cos_F= data_Opal[(data_Opal['ID']== b'mm') & (data_Opal['cos_thet']<0)& (data_Opal['COM_energy']==meanenergy[i])][\"cos_thet\"].to_numpy()\n",
    "    myon_cos_B= data_Opal[(data_Opal['ID']== b'mm') & (data_Opal['cos_thet']<200)& (data_Opal['cos_thet']>0)& (data_Opal['COM_energy']==meanenergy[i])][\"cos_thet\"].to_numpy()\n",
    "\n",
    "    N_ges= len(myon_cos)\n",
    "    N_F= len(myon_cos_F)\n",
    "    N_B= len(myon_cos_B)\n",
    "    N_F_array[i] = N_F\n",
    "    N_B_array[i] = N_B\n",
    "    A_FB[i] = (N_B-N_F)/N_ges\n",
    "\n",
    "A_FB_correction= np.array([0.021512, 0.019262, 0.016713, 0.018293, 0.030286, 0.062196, 0.093850])\n",
    "\n",
    "A_FB= A_FB+A_FB_correction\n",
    "\n",
    "#plt.hist(myon_cos_F, bins= 100)\n",
    "#plt.hist(myon_cos_B, bins= 100)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#plt.plot(meanenergy, A_FB, '.')\n",
    "\n",
    "print('\\n')\n",
    "print('A_FB=', A_FB)\n",
    "\n",
    "#plt.grid()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nf = N_F_array[3]\n",
    "Nb = N_B_array[3]\n",
    "VdA = np.sqrt(A_FB[3]/3)\n",
    "sin2thetaWein = (1-VdA)/4\n",
    "Delta_sin2thetaWein = np.sqrt( np.square( (2*Nf) / (Nb+Nf)**2 * np.sqrt(Nb)) + np.square( (2*Nb) / (Nb+Nf)**2 * np.sqrt(Nb)))\n",
    "print(f'{sin2thetaWein} $\\pm$ {Delta_sin2thetaWein}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lepton universality ##\n",
    "\n",
    "The Lepton universality states, that every decay from particles with high centre-of-mass energy into leptons of any family has the same probability, or stating it in other terms, posses the same crosssection and partial width. For a more convenient comparison, the crossections of the leptons are used, because they are calculated earlier and are thus less frail against systematic errors, e.g. all partial widths depend heavily on the good reproduction of the partial width $\\Gamma_e$ and so on.\n",
    "\n",
    "To compare the crossections, all three values are compared pairwise via the t-test\n",
    "\n",
    "\\begin{align}\n",
    "t-test= \\frac{|a-b|}{\\sqrt{\\sigma_a^2 + \\sigma_b^2}}\n",
    "\\end{align}\n",
    "\n",
    "The two values are comparable, if the value of the t-test is $\\in [0,2]$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def t_test(a,sig_a, b, sig_b):\n",
    "    return np.abs(a-b)/np.sqrt(sig_a**2+sig_b**2)\n",
    "\n",
    "print(crossectionmax[:3])\n",
    "crossectionmax_err= np.array([0.03321685, 0.01366334, 0.01515388, 0.13298636]) # ee, mm, tt, qq\n",
    "print(crossectionmax_err[:3])\n",
    "\n",
    "ttest= np.zeros(3)\n",
    "\n",
    "for i in range(3):\n",
    "    #print(i%3, (i+1)%3)\n",
    "    ttest[i]= t_test(crossectionmax[i%3],crossectionmax_err[i%3], crossectionmax[(i+1)%3], crossectionmax_err[(i+1)%3])\n",
    "\n",
    "print(ttest, '--> only first pair is comparable!')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further the ratios of the Hadron peak crossection with the lepton crossections and its the branching ratios should be calculated.\n",
    "\n",
    "Error propagation is just normal gaussian error propagation from used values, which errors are derived above. Due to time, the exact calculation will just be in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_ratio= np.zeros(3)\n",
    "branching_ratio= np.zeros(5)\n",
    "\n",
    "for i in range(3):\n",
    "    cs_ratio[i]= crossectionmax[i]/crossectionmax[3]\n",
    "\n",
    "for i in range(5):\n",
    "    branching_ratio[i]= Gamma[i]/width\n",
    "\n",
    "print('Crossection ratio      =', cs_ratio, ',  ee/qq, mm/qq, tt/qq')\n",
    "print('partial crossections   =', Gamma, ',  ee, mm, tt, qq, vv(neutrinos)')\n",
    "print('branching ratio        =', branching_ratio, ',  ee, mm, tt, qq, vv(neutrinos)')\n",
    "print('sum of branching ratios=', sum(branching_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
